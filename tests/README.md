# ðŸ§ª Tests Suite

Suite completa de tests unitarios para el proyecto Agentic MLOps.

## ðŸ“‹ Estructura

```
tests/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ test_temporal_generator.py    # Tests para generaciÃ³n temporal
â”œâ”€â”€ test_drift_monitor.py          # Tests para drift detection
â””â”€â”€ README.md                       # Este archivo
```

## ðŸš€ Ejecutar Tests

### Todos los Tests
```bash
pytest tests/ -v
```

### Tests EspecÃ­ficos
```bash
# Solo TemporalHRGenerator
pytest tests/test_temporal_generator.py -v

# Solo DriftMonitor
pytest tests/test_drift_monitor.py -v
```

### Con Coverage
```bash
pytest tests/ -v --cov=src --cov-report=html --cov-report=term
```

### Tests por Marker
```bash
# Solo tests unitarios
pytest -m unit

# Excluir tests lentos
pytest -m "not slow"
```

## ðŸ“Š Cobertura de Tests

### TemporalHRGenerator (test_temporal_generator.py)
- âœ… InicializaciÃ³n bÃ¡sica y con fecha personalizada
- âœ… GeneraciÃ³n de un mes
- âœ… Tasa de retenciÃ³n
- âœ… TamaÃ±o del dataset
- âœ… Secuencia temporal
- âœ… Envejecimiento de empleados
- âœ… CÃ¡lculo de attrition
- âœ… GeneraciÃ³n de nuevos empleados
- âœ… Columna de perÃ­odo
- âœ… Escenarios (normal, recession, etc.)
- âœ… PreservaciÃ³n de tipos de datos
- âœ… ValidaciÃ³n de valores no negativos
- âœ… Independencia de secuencias
- âœ… Casos extremos (dataset pequeÃ±o, alta rotaciÃ³n, 0 meses)

**Total: 20 tests**

### DriftMonitor (test_drift_monitor.py)
- âœ… InicializaciÃ³n bÃ¡sica
- âœ… IdentificaciÃ³n de tipos de columnas
- âœ… CÃ¡lculo de PSI (sin drift y con drift)
- âœ… DetecciÃ³n de covariate shift
- âœ… GeneraciÃ³n de reportes de drift
- âœ… IdentificaciÃ³n de top features con drift
- âœ… ClasificaciÃ³n de severidad
- âœ… Casos extremos (DataFrame vacÃ­o, una columna, solo numÃ©ricas, solo categÃ³ricas)

**Total: 25 tests**

## ðŸŽ¯ Fixtures Disponibles

### test_temporal_generator.py
- `sample_hr_data`: Dataset de 100 empleados con todas las features

### test_drift_monitor.py
- `sample_reference_data`: Datos de referencia (200 registros)
- `sample_current_data_no_drift`: Datos sin drift
- `sample_current_data_with_drift`: Datos con drift significativo

## ðŸ“ Convenciones

### Naming
- Archivos: `test_*.py`
- Clases: `Test*`
- Funciones: `test_*`

### Estructura de Tests
```python
class TestComponentName:
    """Suite de tests para ComponentName."""
    
    def test_feature_basic(self, fixture):
        """Test: DescripciÃ³n breve."""
        # Arrange
        component = Component()
        
        # Act
        result = component.method()
        
        # Assert
        assert result == expected
```

### Markers
```python
@pytest.mark.slow
def test_long_running():
    """Test que toma mucho tiempo."""
    pass

@pytest.mark.integration
def test_with_external_service():
    """Test de integraciÃ³n."""
    pass
```

## ðŸ”§ ConfiguraciÃ³n

### pytest.ini
```ini
[pytest]
testpaths = tests
addopts = -v --tb=short --strict-markers
markers =
    slow: tests lentos
    integration: tests de integraciÃ³n
    unit: tests unitarios
```

### requirements.txt
```
pytest>=7.4.0
pytest-cov>=4.1.0
pytest-mock>=3.11.0
```

## ðŸ“ˆ MÃ©tricas de Calidad

### Coverage Target
- **Objetivo**: >80% de cobertura
- **Actual**: ~85% (componentes principales)

### Test Execution Time
- **Total**: ~5 segundos
- **Por archivo**: <3 segundos

## ðŸ› Debugging Tests

### Ejecutar un test especÃ­fico
```bash
pytest tests/test_temporal_generator.py::TestTemporalHRGenerator::test_initialization -v
```

### Ver output completo
```bash
pytest tests/ -v -s
```

### Modo debug con pdb
```bash
pytest tests/ --pdb
```

### Ver warnings
```bash
pytest tests/ -v -W all
```

## ðŸš§ Tests Pendientes

### Alta Prioridad
- [ ] Tests para TemporalValidator
- [ ] Tests de integraciÃ³n end-to-end
- [ ] Tests para train_pipeline_temporal.py

### Media Prioridad
- [ ] Tests de performance
- [ ] Tests de carga
- [ ] Tests de regresiÃ³n

### Baja Prioridad
- [ ] Tests de UI (Streamlit)
- [ ] Tests de API (FastAPI)

## ðŸ’¡ Best Practices

### âœ… DO
- Usar fixtures para datos de prueba
- Mantener tests independientes
- Usar nombres descriptivos
- Probar casos extremos
- Mantener tests rÃ¡pidos

### âŒ DON'T
- Depender de orden de ejecuciÃ³n
- Usar datos de producciÃ³n
- Hacer tests demasiado complejos
- Ignorar tests fallidos
- Hardcodear valores mÃ¡gicos

## ðŸ”— Referencias

- [Pytest Documentation](https://docs.pytest.org/)
- [Testing Best Practices](https://docs.python-guide.org/writing/tests/)
- [Coverage.py](https://coverage.readthedocs.io/)

## ðŸ“ž Soporte

Para problemas con tests:
1. Verificar que todas las dependencias estÃ¡n instaladas: `pip install -r requirements.txt`
2. Verificar que PYTHONPATH incluye el directorio raÃ­z
3. Revisar logs de ejecuciÃ³n con `-v -s`

---

*Tests mantienen la calidad del cÃ³digo y previenen regresiones*